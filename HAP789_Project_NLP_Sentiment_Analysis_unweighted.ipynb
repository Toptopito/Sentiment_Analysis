{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word or phrase list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# read checkpoint file\n",
    "main_df = pd.read_csv('./data/checkpoint_05_synonyms.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate word phrase list from text\n",
    "def generate_word_phrase_list(text):\n",
    "    text_list = text.split()\n",
    "    end_pos = len(text_list)\n",
    "    word_phrase_list = []\n",
    "    \n",
    "    for i in range(end_pos):\n",
    "        for j in range(i, end_pos):\n",
    "            words = text_list[i:j+1]\n",
    "            phrase = ' '.join(words)\n",
    "            word_phrase_list.append(phrase)\n",
    "    \n",
    "    return word_phrase_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "      <th>word_phrase_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>moral story nurse great body money</td>\n",
       "      <td>[moral, moral story, moral story nurse, moral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>think better appearance want competent</td>\n",
       "      <td>[think, think better, think better appearance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel concern brush aside go collapse</td>\n",
       "      <td>[feel, feel concern, feel concern brush, feel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>tear trough filler leave eye look like garage</td>\n",
       "      <td>[tear, tear trough, tear trough filler, tear t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank encourage way</td>\n",
       "      <td>[thank, thank encourage, thank encourage way, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                              comment_processed  \\\n",
       "0               0             moral story nurse great body money   \n",
       "1               0         think better appearance want competent   \n",
       "2               1           feel concern brush aside go collapse   \n",
       "3               1  tear trough filler leave eye look like garage   \n",
       "4               0                            thank encourage way   \n",
       "\n",
       "                                    word_phrase_list  \n",
       "0  [moral, moral story, moral story nurse, moral ...  \n",
       "1  [think, think better, think better appearance,...  \n",
       "2  [feel, feel concern, feel concern brush, feel ...  \n",
       "3  [tear, tear trough, tear trough filler, tear t...  \n",
       "4  [thank, thank encourage, thank encourage way, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing values for comment_processed\n",
    "main_df = main_df.dropna(subset=['comment_processed'])\n",
    "\n",
    "# Apply the generate_word_phrase_list function to the comment_processed column to create word_phrase_list column\n",
    "main_df['word_phrase_list'] = main_df['comment_processed'].apply(generate_word_phrase_list)\n",
    "\n",
    "# Output the DataFrame with word phrase list\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final cleanups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop invalid comments from test selection\n",
    "# List of commentIds to drop\n",
    "commentIds_to_drop = [181673, 95658]\n",
    "\n",
    "# Drop rows with specified commentIds\n",
    "selection_df = main_df[~main_df['commentId'].isin(commentIds_to_drop)]\n",
    "\n",
    "# Check if each value in the 'comment_processed' column contains only one word\n",
    "is_single_word = selection_df['comment_processed'].str.split().apply(len) == 1\n",
    "\n",
    "# Keep rows where the comment_processed column has more than one word\n",
    "selection_df = selection_df[~is_single_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test and training sets and calculate similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "      <th>word_phrase_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84833</td>\n",
       "      <td>The doctor talked to me with half his body in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>doctor talk body examination room</td>\n",
       "      <td>[doctor, doctor talk, doctor talk body, doctor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58035</td>\n",
       "      <td>And the registration person was not so nice.</td>\n",
       "      <td>1</td>\n",
       "      <td>registration person not nice</td>\n",
       "      <td>[registration, registration person, registrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190897</td>\n",
       "      <td>This is a pretend clinic they pretend to love ...</td>\n",
       "      <td>1</td>\n",
       "      <td>pretend clinic pretend love look fund</td>\n",
       "      <td>[pretend, pretend clinic, pretend clinic prete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173845</td>\n",
       "      <td>When I complained about it, I was asked to sen...</td>\n",
       "      <td>1</td>\n",
       "      <td>complain ask send picture</td>\n",
       "      <td>[complain, complain ask, complain ask send, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168214</td>\n",
       "      <td>Acts like a history teacher when really he's a...</td>\n",
       "      <td>1</td>\n",
       "      <td>act like history teacher dumb doctor keep ask ...</td>\n",
       "      <td>[act, act like, act like history, act like his...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0      84833  The doctor talked to me with half his body in ...   \n",
       "1      58035     And the registration person was not so nice.     \n",
       "2     190897  This is a pretend clinic they pretend to love ...   \n",
       "3     173845  When I complained about it, I was asked to sen...   \n",
       "4     168214  Acts like a history teacher when really he's a...   \n",
       "\n",
       "   classification                                  comment_processed  \\\n",
       "0               1                  doctor talk body examination room   \n",
       "1               1                       registration person not nice   \n",
       "2               1              pretend clinic pretend love look fund   \n",
       "3               1                          complain ask send picture   \n",
       "4               1  act like history teacher dumb doctor keep ask ...   \n",
       "\n",
       "                                    word_phrase_list  \n",
       "0  [doctor, doctor talk, doctor talk body, doctor...  \n",
       "1  [registration, registration person, registrati...  \n",
       "2  [pretend, pretend clinic, pretend clinic prete...  \n",
       "3  [complain, complain ask, complain ask send, co...  \n",
       "4  [act, act like, act like history, act like his...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where classification is 1\n",
    "complaints_df = selection_df[selection_df['classification'] == 1].sample(n=35, random_state=42)\n",
    "\n",
    "# Filter rows where classification is 0\n",
    "praises_df = selection_df[selection_df['classification'] == 0].sample(n=35, random_state=42)\n",
    "\n",
    "# Concatenate both dataframes\n",
    "test_df = pd.concat([complaints_df, praises_df])\n",
    "\n",
    "# Reset index of the resulting dataframe\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Create a folder for training files if it doesn't exist\n",
    "if not os.path.exists('./training_files'):\n",
    "    os.makedirs('./training_files')\n",
    "\n",
    "# Loop through each row in test_df\n",
    "for i in range(len(test_df)):\n",
    "    test_row = test_df.iloc[[i]] # get current row in dataframe format\n",
    "    \n",
    "    # Create a copy of main_df\n",
    "    train_df = main_df.copy()\n",
    "\n",
    "    # Remove the row with the same commentId as the current row in test_df\n",
    "    test_commentId = int(test_row['commentId'])\n",
    "\n",
    "    train_df = train_df[train_df['commentId'] != test_commentId]\n",
    "\n",
    "    # Get word_phrase_list of current row in test_df and create columns in train_df\n",
    "    word_phrase_list = test_row['word_phrase_list'][i]\n",
    "\n",
    "    for word_phrase in word_phrase_list:\n",
    "        train_df[word_phrase] = 0 # init to 0\n",
    "\n",
    "    # Set the word_phrase column to 1 if it exists in the training set row (exact match)\n",
    "    for word_phrase in word_phrase_list:\n",
    "        train_df[word_phrase] = train_df['word_phrase_list'].apply(lambda x: 1 if word_phrase in x else 0)\n",
    "        \n",
    "    # Remove rows where the sum of the columns created from word_phrase_list is 0\n",
    "    train_df = train_df[train_df[word_phrase_list].sum(axis=1) != 0]\n",
    "\n",
    "    # Get columns present in the word_phrase_list\n",
    "    word_phrase_columns = train_df.columns[train_df.columns.isin(word_phrase_list)]\n",
    "    \n",
    "    # Get all columns that are all ones or zeros within word_phrase_columns\n",
    "    columns_to_drop = word_phrase_columns[(train_df[word_phrase_columns].sum(axis=0) == len(train_df)) | (train_df[word_phrase_columns].sum(axis=0) == 0)]\n",
    "    \n",
    "    # Drop these columns with all ones or zeros (zero variance)\n",
    "    train_df = train_df.drop(columns=columns_to_drop)\n",
    "       \n",
    "    # Create filename\n",
    "    filename = f\"./training_files/unweighted/{test_commentId}.csv\"\n",
    "\n",
    "    # Write dataframe to CSV\n",
    "    train_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "test_df.to_csv('./data/test_df_initial_unweighted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Similarity Scores as Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate probability of complaint\n",
    "def calculate_probability(intercept, coefficients):\n",
    "    sumcoeff = intercept + np.sum(coefficients)\n",
    "    return 1 / (1 + np.exp(-sumcoeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loop each row in test_df and calculate prediction, TP, TN, FP, FN\n",
    "i = 0\n",
    "cutoff = 0.5 # probability cutoff for prediction\n",
    "for index, row in test_df.iterrows():\n",
    "    # get commentId\n",
    "    comment_id = row['commentId']\n",
    "\n",
    "    # open training file for test row\n",
    "    filename = f\"./training_files/unweighted/{comment_id}.csv\"\n",
    "    train_df = pd.read_csv(filename, low_memory=False)\n",
    "\n",
    "    # set target variable\n",
    "    y = train_df['classification']\n",
    "\n",
    "    # set independent variables\n",
    "    cols_to_drop = ['classification',\n",
    "                    'commentId',\n",
    "                    'comment',\n",
    "                    'comment_processed',\n",
    "                    'word_phrase_list'\n",
    "                    ]\n",
    "    X = train_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Do logistic regression modeling with similarity_score as weight\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "    \n",
    "    # create a column in the test_df for the predicted probability \n",
    "    test_df.at[index, 'probability'] = calculate_probability(log_reg.intercept_[0], log_reg.coef_[0]) \n",
    "\n",
    "    # calculate prediction from probability using cutoff\n",
    "    test_df.at[index, 'prediction'] = 1 if test_df.at[index, 'probability'] >= cutoff else 0\n",
    "\n",
    "    # calculate calibration\n",
    "    test_df.at[index, 'calibration'] = abs(test_df.at[index, 'probability'] - test_df.at[index, 'classification'])\n",
    "    \n",
    "    # Calculate TP, TN, FP, FN\n",
    "    test_df.at[index, 'TP'] = 1 if (test_df.at[index, 'prediction'] == 1 and test_df.at[index, 'classification'] == 1) else 0\n",
    "    test_df.at[index, 'TN'] = 1 if (test_df.at[index, 'prediction'] == 0 and test_df.at[index, 'classification'] == 0) else 0\n",
    "    test_df.at[index, 'FP'] = 1 if (test_df.at[index, 'prediction'] == 1 and test_df.at[index, 'classification'] == 0) else 0\n",
    "    test_df.at[index, 'FN'] = 1 if (test_df.at[index, 'prediction'] == 0 and test_df.at[index, 'classification'] == 1) else 0\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "test_df.to_csv('./data/test_df_completed_unweighted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING REGRESSION PREDICTION\n",
      "CONFUSION MATRIX:\n",
      "TP: 28.0 | FP: 3.0\n",
      "FN: 7.0 | TN: 32.0\n",
      "\n",
      "\n",
      "Model accuracy: 85.71%\n",
      "Average of calibration: 0.22\n",
      "Standard deviation of calibration: 0.24\n"
     ]
    }
   ],
   "source": [
    "# For entire test_df calculate accuracy\n",
    "TP = test_df['TP'].sum()\n",
    "TN = test_df['TN'].sum()\n",
    "FP = test_df['FP'].sum()\n",
    "FN = test_df['FN'].sum()\n",
    "accuracy = round((TP + TN) / (TP + TN + FP + FN) * 100, 2)\n",
    "\n",
    "# Calculate average calibration and its standard deviation\n",
    "average_calibration = round(test_df['calibration'].mean(),2)\n",
    "std_dev_calibration = round(test_df['calibration'].std(),2)\n",
    "\n",
    "print(\"USING REGRESSION PREDICTION\")\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(f\"TP: {TP} | FP: {FP}\")\n",
    "print(f\"FN: {FN} | TN: {TN}\")\n",
    "print(f\"\\n\\nModel accuracy: {accuracy}%\")\n",
    "print(f\"Average of calibration: {average_calibration}\")\n",
    "print(f\"Standard deviation of calibration: {std_dev_calibration}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
