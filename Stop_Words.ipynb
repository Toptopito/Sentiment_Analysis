{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fe97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2326364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "# Load English model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317aa2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of English stop words\n",
    "stop_words = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f065960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the stop words into a DataFrame\n",
    "stop_words_df = pd.DataFrame({\"Stop_Words\": list(stop_words)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67497b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "stop_words_df.to_csv(\"english_stop_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f872ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541435d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a05e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom list of stop words\n",
    "custom_stop_words = [\"although\", \"her\", \"whole\", \"an\", \"whereupon\", \"within\" \"doing\", \"when\", \"whose\", \"until\", \"into\", \"whereby\", \n",
    "                     \"together\", \"before\", \"now\", \"must\", \"anyhow\", \"whenever\", \"becomes\", \"yet\" \"these\", \"anything\", \"give\", \"regarding\", \"had\", \"am\", \"thereby\", \"therein\", \"two\", \"up\", \"wherever\", \n",
    "                     \"onto\", \"though\", \"nevertheless\", \"upon\", \"please\", \"seem\", \"amount\", \"anyone\", \"every\", \"hence\", \"them\", \"there\", \"side\", \"enough\", \n",
    "                     \"put\", \"their\", \"throughout\", \"below\", \"but\", \"myself\", \"are\", \"say\", \"almost\", \"ourselves\" \"last\", \"thus\", \"latterly\", \"done\", \"under\",\n",
    "                     \"nothing\", \"herself\", \"such\", \"noone\", \"yourselves\", \"across\", \"hereafter\", \"themselves\", \"seems\", \"again\", \"through\", \"whither\", \"thereupon\", \"whether\", \"on\", \"becoming\", \"that\", \"us\", \"become\", \"eight\", \"everyone\", \n",
    "                     \"its\", \"would\", \"in\", \"fifteen\", \"too\", \"could\", \"due\", \"whatever\", \"toward\", \"well\", \"after\", \"using\", \"already\", \"much\", \"namely\", \"should\", \"to\", \"made\", \"him\", \n",
    "                     \"each\", \"she\", \"he\", \"both\", \"me\", \"various\", \"my\", \"ever\", \"eleven\", \"one\", \"serious\", \"between\", \"yourself\", \"few\", \"really\", \"hereby\", \"besides\", \"can\", \"beyond\", \"at\", \"has\", \"amongst\", \n",
    "                     \"less\", \"anywhere\", \"sixty\", \"still\", \"what\", \"front\", \"during\", \"who\", \"several\", \"been\", \"herein\", \"does\", \"used\", \"from\", \"fifty\", \"mostly\", \n",
    "                     \"beside\", \"we\", \"four\", \"everywhere\", \"for\", \"his\", \"down\", \"will\", \"did\", \"where\", \"hundred\", \"none\", \"of\", \"sometime\", \"whereafter\", \"around\", \"get\", \"twelve\", \"ca\", \"move\", \"very\", \"your\", \"our\", \"beforehand\", \"forty\", \"over\", \"behind\", \n",
    "                     \"hereupon\", \"the\", \"as\", \"just\", \"except\", \"same\", \"than\", \"it\", \"however\", \"along\", \"full\", \"about\", \"was\", \"perhaps\", \"back\", \"a\" \"nowhere\", \"mine\", \"keep\", \"anyway\", \"have\", \"thru\", \"top\", \"see\", \"thence\", \"meanwhile\",\n",
    "                     \"some\", \"hers\", \"otherwise\", \"be\", \"yours\", \"why\", \"against\", \"indeed\", \"moreover\", \"third\", \"first\", \"seemed\", \"something\", \"quite\", \"or\", \"whoever\", \"part\", \"once\", \"others\", \"therefore\", \"alone\", \"here\", \"is\", \"next\", \"this\", \n",
    "                     \"how\", \"so\", \"you\", \"seeming\", \"five\", \"more\", \"everything\", \"all\", \"somewhere\", \"may\", \"whom\", \"per\", \"another\", \"twenty\", \"make\", \"most\", \"show\", \"go\", \"further\", \"and\", \"itself\", \"three\", \"somehow\", \"name\", \"often\", \"among\", \"take\", \n",
    "                     \"wherein\", \"while\", \"ours\", \"always\", \"thereafter\", \"rather\", \"they\", \"nine\", \"became\", \"only\", \"then\", \"formerly\", \"because\", \"empty\", \"those\", \"ten\", \"do\", \"via\", \"himself\", \"other\", \"else\", \"former\", \"any\", \"by\", \"which\", \"unless\", \"since\", \n",
    "                     \"sometimes\", \"many\", \"six\", \"whereas\", \"also\", \"above\", \"even\", \"with\", \"someone\", \"were\", \"if\", \"least\", \"elsewhere\", \"might\", \"afterwards\", \"out\", \"either\", \"own\", \"bottom\", \"off\", \"whence\", \"latter\", \"being\", \"call\", \"towards\", \"without\", \"few\",\n",
    "                    \"never\", \"nowhere\", \"nobody\", \"none\", \"a\", \"he\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bebfa316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the custom stop words to spaCy's default stop words\n",
    "for word in custom_stop_words:\n",
    "    nlp.Defaults.stop_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd5fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Text: example sentence want remove .\n"
     ]
    }
   ],
   "source": [
    "# Example text with custom stop words\n",
    "text = \"This is an example sentence with although and her that we want to remove.\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Filter out the stop words\n",
    "filtered_text = \" \".join(token.text for token in doc if not token.is_stop)\n",
    "\n",
    "print(\"Filtered Text:\", filtered_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ae424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
