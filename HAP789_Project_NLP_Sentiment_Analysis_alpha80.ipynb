{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and initial data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>dateCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-03 18:15:21.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-30 21:10:15.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-12 17:05:36.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-12 17:13:43.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-09 02:31:02.590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification              dateCreated  \n",
       "0               0  2019-06-03 18:15:21.263  \n",
       "1               0  2022-04-30 21:10:15.950  \n",
       "2               1  2015-10-12 17:05:36.043  \n",
       "3               1  2020-07-12 17:13:43.700  \n",
       "4               0  2019-10-09 02:31:02.590  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv('./data/TrainingRecords-4-4-2024.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dateCreated column\n",
    "df = df.drop(columns=['dateCreated'])\n",
    "\n",
    "# Remove duplicates based on commentId and keep the first occurrence\n",
    "df = df.drop_duplicates(subset='commentId', keep='first').reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with missing values for comments\n",
    "df = df.dropna(subset=['comment'])\n",
    "\n",
    "# drop invalid comments\n",
    "# List of commentIds to drop\n",
    "commentIds_to_drop = [180459, 151656, 179845, 179923]\n",
    "\n",
    "# Drop rows with specified commentIds\n",
    "df = df[~df['commentId'].isin(commentIds_to_drop)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 105778 entries, 0 to 105782\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   commentId       105778 non-null  int64 \n",
      " 1   comment         105778 non-null  object\n",
      " 2   classification  105778 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                                  comment_processed  \n",
       "0               0  Moral of the story while the nurses are all gr...  \n",
       "1               0  If you are thinking about improving your appea...  \n",
       "2               1  but I felt that my concerns were brushed aside...  \n",
       "3               1  My tear trough filler in my left eye looked li...  \n",
       "4               0  So, thank you Dr. Whitaker for all you have do...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create copy of dataframe that can be used for further processing\n",
    "main_df = df.copy()\n",
    "\n",
    "# Create comment_processed column\n",
    "main_df['comment_processed'] = main_df['comment']\n",
    "\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove special characters and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import re # for regular expressions\n",
    "\n",
    "# Remove punctuation, special characters, and numbers\n",
    "main_df['comment_processed'] = main_df['comment_processed'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change all to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comment_processed column with lower case comments\n",
    "main_df['comment_processed'] = main_df['comment_processed'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import spacy\n",
    "\n",
    "# Load English language model with named entity recognition (NER) component\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to remove proper nouns from text\n",
    "def remove_proper_nouns(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = [token.text for token in doc if token.ent_type_ == \"\"]\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the remove_proper_nouns function to the comment_processed column\n",
    "main_df['comment_processed'] = main_df['comment_processed'].apply(remove_proper_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>moral of the story while the nurses are all gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>if you are thinking about improving your appea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>but i felt that my concerns were brushed aside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>my tear trough filler in my left eye looked li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>so thank you for all you have done and how enc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                                  comment_processed  \n",
       "0               0  moral of the story while the nurses are all gr...  \n",
       "1               0  if you are thinking about improving your appea...  \n",
       "2               1  but i felt that my concerns were brushed aside...  \n",
       "3               1  my tear trough filler in my left eye looked li...  \n",
       "4               0  so thank you for all you have done and how enc...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with empty comment_processed column\n",
    "main_df = main_df[main_df['comment_processed'].notnull() & (main_df['comment_processed'] != '')]\n",
    "\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with removed proper nouns\n",
    "main_df.to_csv('./data/checkpoint_01_no_proper.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing (complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# read checkpoint file\n",
    "main_df = pd.read_csv('./data/checkpoint_01_no_proper.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Function to correct spelling mistakes in a text\n",
    "def correct_spelling(text):\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = blob.correct()\n",
    "    return str(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>moral of the story while the nurses are all gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>if you are thinking about improving your appea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>but i felt that my concerns were brushed aside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>my tear trough filler in my left eye looked li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>so thank you for all you have done and how enc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                                  comment_processed  \n",
       "0               0  moral of the story while the nurses are all gr...  \n",
       "1               0  if you are thinking about improving your appea...  \n",
       "2               1  but i felt that my concerns were brushed aside...  \n",
       "3               1  my tear trough filler in my left eye looked li...  \n",
       "4               0  so thank you for all you have done and how enc...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the correct_spelling function to the comment_processed column\n",
    "main_df['comment_processed'] = main_df['comment_processed'].apply(correct_spelling)\n",
    "\n",
    "# Output the DataFrame with corrected spelling\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with empty comment_processed column\n",
    "main_df = main_df[main_df['comment_processed'].notnull() & (main_df['comment_processed'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "main_df.to_csv('./data/checkpoint_02_spell_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stop words (caution \"no\", \"not\" and other relevant negation words should not be removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# read checkpoint file\n",
    "main_df = pd.read_csv('./data/checkpoint_02_spell_corrected.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Get the list of English stop words\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Convert the stop words into a DataFrame\n",
    "stop_words_df = pd.DataFrame({\"Stop_Words\": list(stop_words)})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "stop_words_df.to_csv(\"./data/spacy_english_stop_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After processing the spacy stop word list create a custom stop word list and replace spacy stop words\n",
    "custom_stop_words_df = pd.read_csv(\"./data/spacy_english_stop_words_processed.csv\")\n",
    "custom_stop_words = custom_stop_words_df['Stop_Words'].tolist()\n",
    "nlp.Defaults.stop_words = custom_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to remove custom stop words\n",
    "def remove_stop_words(text):\n",
    "\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Filter out the stop words\n",
    "    filtered_text = \" \".join(token.text for token in doc if not token.is_stop)\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stop word removal function to the comment_processed column\n",
    "main_df['comment_processed'] = main_df['comment_processed'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>moral story nurses great body money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>thinking improving appearance want competent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>felt concerns brushed aside went collapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>tear trough filler left eye looked like garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank encouraging way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                               comment_processed  \n",
       "0               0             moral story nurses great body money  \n",
       "1               0    thinking improving appearance want competent  \n",
       "2               1       felt concerns brushed aside went collapse  \n",
       "3               1  tear trough filler left eye looked like garage  \n",
       "4               0                           thank encouraging way  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with empty comment_processed column\n",
    "main_df = main_df[main_df['comment_processed'].notnull() & (main_df['comment_processed'] != '')]\n",
    "\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "main_df.to_csv('./data/checkpoint_03_no_stop_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# read checkpoint file\n",
    "main_df = pd.read_csv('./data/checkpoint_03_no_stop_words.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize a single comment\n",
    "def lemmatize_comment(comment):\n",
    "    if comment == '' or comment is None:\n",
    "        return ''  # Return an empty string if it's NaN\n",
    "    \n",
    "    tokens = word_tokenize(comment)  # Tokenize the comment into words\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize each word\n",
    "    return ' '.join(lemmatized_tokens)  # Join the lemmatized tokens back into a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the lemmatize function to the comment_processed column\n",
    "main_df['comment_processed'] = main_df['comment_processed'].apply(lemmatize_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>moral story nurse great body money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>thinking improving appearance want competent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>felt concern brushed aside went collapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>tear trough filler left eye looked like garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank encouraging way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                               comment_processed  \n",
       "0               0              moral story nurse great body money  \n",
       "1               0    thinking improving appearance want competent  \n",
       "2               1        felt concern brushed aside went collapse  \n",
       "3               1  tear trough filler left eye looked like garage  \n",
       "4               0                           thank encouraging way  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with empty comment_processed column\n",
    "main_df = main_df[main_df['comment_processed'].notnull() & (main_df['comment_processed'] != '')]\n",
    "\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "main_df.to_csv('./data/checkpoint_04_lemmatized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# read checkpoint file\n",
    "main_df = pd.read_csv('./data/checkpoint_04_lemmatized.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # Adding this line to download the required \"omw-1.4\" resource\n",
    "\n",
    "# Function to find the most common synonym for a word using WordNet\n",
    "def most_common_synonym(word):\n",
    "    synsets = wordnet.synsets(word)  # Get all synsets for the word\n",
    "    if synsets:\n",
    "        all_synonyms = [syn.lemmas() for syn in synsets]  # Get all lemmas for each synset\n",
    "        all_synonyms = [lemma.name().replace('_', ' ') for syn in all_synonyms for lemma in syn]  # Flatten the list of lemmas, replacing underscores with spaces\n",
    "        synonym_counts = {synonym: all_synonyms.count(synonym) for synonym in all_synonyms}  # Count occurrences of each synonym\n",
    "        most_common_synonym = max(synonym_counts, key=synonym_counts.get)  # Get the synonym with the highest count\n",
    "        return most_common_synonym.lower()\n",
    "    else:\n",
    "        return word  # If no synsets found, return the original word\n",
    "\n",
    "# Function to replace each word in a comment with its most common synonym\n",
    "def replace_with_synonyms(comment):\n",
    "    tokens = word_tokenize(comment)  # Tokenize the comment into words\n",
    "    replaced_tokens = [most_common_synonym(token) for token in tokens]  # Replace each word with its most common synonym\n",
    "    return ' '.join(replaced_tokens)  # Join the replaced tokens back into a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the synonym function to the comment_processed column\n",
    "main_df['comment_processed'] = main_df['comment_processed'].apply(replace_with_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>moral story nurse great body money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>think better appearance want competent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel concern brush aside go collapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>tear trough filler leave eye look like garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank encourage way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                              comment_processed  \n",
       "0               0             moral story nurse great body money  \n",
       "1               0         think better appearance want competent  \n",
       "2               1           feel concern brush aside go collapse  \n",
       "3               1  tear trough filler leave eye look like garage  \n",
       "4               0                            thank encourage way  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with empty comment_processed column\n",
    "main_df = main_df[main_df['comment_processed'].notnull() & (main_df['comment_processed'] != '')]\n",
    "\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "main_df.to_csv('./data/checkpoint_05_synonyms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word or phrase list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# read checkpoint file\n",
    "main_df = pd.read_csv('./data/checkpoint_05_synonyms.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate word phrase list from text\n",
    "def generate_word_phrase_list(text):\n",
    "    text_list = text.split()\n",
    "    end_pos = len(text_list)\n",
    "    word_phrase_list = []\n",
    "    \n",
    "    for i in range(end_pos):\n",
    "        for j in range(i, end_pos):\n",
    "            words = text_list[i:j+1]\n",
    "            phrase = ' '.join(words)\n",
    "            word_phrase_list.append(phrase)\n",
    "    \n",
    "    return word_phrase_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "      <th>word_phrase_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129687</td>\n",
       "      <td>Moral of the story while the nurses are all gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>moral story nurse great body money</td>\n",
       "      <td>[moral, moral story, moral story nurse, moral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169075</td>\n",
       "      <td>If you are thinking about improving your appea...</td>\n",
       "      <td>0</td>\n",
       "      <td>think better appearance want competent</td>\n",
       "      <td>[think, think better, think better appearance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88567</td>\n",
       "      <td>but I felt that my concerns were brushed aside...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel concern brush aside go collapse</td>\n",
       "      <td>[feel, feel concern, feel concern brush, feel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147104</td>\n",
       "      <td>My tear trough filler in my left eye looked li...</td>\n",
       "      <td>1</td>\n",
       "      <td>tear trough filler leave eye look like garage</td>\n",
       "      <td>[tear, tear trough, tear trough filler, tear t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137347</td>\n",
       "      <td>So, thank you Dr. Whitaker for all you have do...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank encourage way</td>\n",
       "      <td>[thank, thank encourage, thank encourage way, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     129687  Moral of the story while the nurses are all gr...   \n",
       "1     169075  If you are thinking about improving your appea...   \n",
       "2      88567  but I felt that my concerns were brushed aside...   \n",
       "3     147104  My tear trough filler in my left eye looked li...   \n",
       "4     137347  So, thank you Dr. Whitaker for all you have do...   \n",
       "\n",
       "   classification                              comment_processed  \\\n",
       "0               0             moral story nurse great body money   \n",
       "1               0         think better appearance want competent   \n",
       "2               1           feel concern brush aside go collapse   \n",
       "3               1  tear trough filler leave eye look like garage   \n",
       "4               0                            thank encourage way   \n",
       "\n",
       "                                    word_phrase_list  \n",
       "0  [moral, moral story, moral story nurse, moral ...  \n",
       "1  [think, think better, think better appearance,...  \n",
       "2  [feel, feel concern, feel concern brush, feel ...  \n",
       "3  [tear, tear trough, tear trough filler, tear t...  \n",
       "4  [thank, thank encourage, thank encourage way, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing values for comment_processed\n",
    "main_df = main_df.dropna(subset=['comment_processed'])\n",
    "\n",
    "# Apply the generate_word_phrase_list function to the comment_processed column to create word_phrase_list column\n",
    "main_df['word_phrase_list'] = main_df['comment_processed'].apply(generate_word_phrase_list)\n",
    "\n",
    "# Output the DataFrame with word phrase list\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "main_df.to_csv('./data/checkpoint_06_final_training_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final cleanups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop invalid comments from test selection\n",
    "# List of commentIds to drop\n",
    "commentIds_to_drop = [181673, 95658]\n",
    "\n",
    "# Drop rows with specified commentIds\n",
    "selection_df = main_df[~main_df['commentId'].isin(commentIds_to_drop)]\n",
    "\n",
    "# Check if each value in the 'comment_processed' column contains only one word\n",
    "is_single_word = selection_df['comment_processed'].str.split().apply(len) == 1\n",
    "\n",
    "# Keep rows where the comment_processed column has more than one word\n",
    "selection_df = selection_df[~is_single_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test and training sets and calculate similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>comment</th>\n",
       "      <th>classification</th>\n",
       "      <th>comment_processed</th>\n",
       "      <th>word_phrase_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126376</td>\n",
       "      <td>I have been in an incredible amount of pain wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>incredible pain ignore doctor</td>\n",
       "      <td>[incredible, incredible pain, incredible pain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188698</td>\n",
       "      <td>un-returned phone call post surgery after a co...</td>\n",
       "      <td>1</td>\n",
       "      <td>return phone post surgery concern report</td>\n",
       "      <td>[return, return phone, return phone post, retu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182819</td>\n",
       "      <td>and I feel like the bodytite was not worth it ...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel like bodytite worth mind kiss dramaticall...</td>\n",
       "      <td>[feel, feel like, feel like bodytite, feel lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155926</td>\n",
       "      <td>Two years later the improvements are nowhere t...</td>\n",
       "      <td>1</td>\n",
       "      <td>improvement see</td>\n",
       "      <td>[improvement, improvement see, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116285</td>\n",
       "      <td>My skin on the side of my face is still numb.</td>\n",
       "      <td>1</td>\n",
       "      <td>skin face numb</td>\n",
       "      <td>[skin, skin face, skin face numb, face, face n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                                            comment  \\\n",
       "0     126376  I have been in an incredible amount of pain wh...   \n",
       "1     188698  un-returned phone call post surgery after a co...   \n",
       "2     182819  and I feel like the bodytite was not worth it ...   \n",
       "3     155926  Two years later the improvements are nowhere t...   \n",
       "4     116285      My skin on the side of my face is still numb.   \n",
       "\n",
       "   classification                                  comment_processed  \\\n",
       "0               1                      incredible pain ignore doctor   \n",
       "1               1           return phone post surgery concern report   \n",
       "2               1  feel like bodytite worth mind kiss dramaticall...   \n",
       "3               1                                    improvement see   \n",
       "4               1                                     skin face numb   \n",
       "\n",
       "                                    word_phrase_list  \n",
       "0  [incredible, incredible pain, incredible pain ...  \n",
       "1  [return, return phone, return phone post, retu...  \n",
       "2  [feel, feel like, feel like bodytite, feel lik...  \n",
       "3                [improvement, improvement see, see]  \n",
       "4  [skin, skin face, skin face numb, face, face n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where classification is 1\n",
    "complaints_df = selection_df[selection_df['classification'] == 1].sample(n=35, random_state=42)\n",
    "\n",
    "# Filter rows where classification is 0\n",
    "praises_df = selection_df[selection_df['classification'] == 0].sample(n=35, random_state=42)\n",
    "\n",
    "# Concatenate both dataframes\n",
    "test_df = pd.concat([complaints_df, praises_df])\n",
    "\n",
    "# Reset index of the resulting dataframe\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate similarity score\n",
    "def calculate_similarity_score(row, alpha, word_phrase_list):\n",
    "    n_match = row[word_phrase_list].sum(axis=1) # number of matches\n",
    "    n_target_only = len(word_phrase_list) - n_match # number unmatched in target\n",
    "    n_train_only = len(row['word_phrase_list']) - n_match # number unmatched in training\n",
    "\n",
    "    similarity_score = (n_match / (n_match + (alpha * n_target_only) + ((1-alpha) * n_train_only)))\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set alpha for similarity score\n",
    "alpha = 0.8 # may need to change for sensitivity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"DataFrame is highly fragmented\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Create a folder for training files if it doesn't exist\n",
    "if not os.path.exists('./training_files'):\n",
    "    os.makedirs('./training_files')\n",
    "\n",
    "# Loop through each row in test_df\n",
    "for i in range(len(test_df)):\n",
    "    test_row = test_df.iloc[[i]] # get current row in dataframe format\n",
    "    \n",
    "    # Create a copy of main_df\n",
    "    train_df = main_df.copy()\n",
    "\n",
    "    # Remove the row with the same commentId as the current row in test_df\n",
    "    test_commentId = int(test_row['commentId'])\n",
    "    train_df = train_df[train_df['commentId'] != test_commentId]\n",
    "\n",
    "    # Get word_phrase_list of current row in test_df and create columns in train_df\n",
    "    word_phrase_list = test_row['word_phrase_list'][i]\n",
    "\n",
    "    for word_phrase in word_phrase_list:\n",
    "        train_df[word_phrase] = 0 # init to 0\n",
    "\n",
    "    # Set the word_phrase column to 1 if it exists in the training set row (exact match)\n",
    "    for word_phrase in word_phrase_list:\n",
    "        train_df[word_phrase] = train_df['word_phrase_list'].apply(lambda x: 1 if word_phrase in x else 0)\n",
    "        \n",
    "    # Remove rows where the sum of the columns created from word_phrase_list is 0\n",
    "    train_df = train_df[train_df[word_phrase_list].sum(axis=1) != 0]\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    train_df['similarity_score'] = 0.0 # initialize\n",
    "    \n",
    "    j = 0\n",
    "    for index, row in train_df.iterrows():\n",
    "        train_row = train_df.iloc[[j]] # get current row in dataframe format\n",
    "        train_df.at[index, 'similarity_score'] = calculate_similarity_score(train_row, alpha, word_phrase_list)\n",
    "        j += 1\n",
    "    \n",
    "    # Get columns present in the word_phrase_list\n",
    "    word_phrase_columns = train_df.columns[train_df.columns.isin(word_phrase_list)]\n",
    "    \n",
    "    # Get all columns that are all ones or zeros within word_phrase_columns\n",
    "    columns_to_drop = word_phrase_columns[(train_df[word_phrase_columns].sum(axis=0) == len(train_df)) | (train_df[word_phrase_columns].sum(axis=0) == 0)]\n",
    "    \n",
    "    # Drop these columns with all ones or zeros (zero variance)\n",
    "    train_df = train_df.drop(columns=columns_to_drop)\n",
    "       \n",
    "    # Create filename\n",
    "    filename = f\"./training_files/{test_commentId}.csv\"\n",
    "\n",
    "    # Write dataframe to CSV\n",
    "    train_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "test_df.to_csv('./data/test_df_initial_alpha80.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Similarity Scores as Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate probability of complaint\n",
    "def calculate_probability(intercept, coefficients):\n",
    "    sumcoeff = intercept + np.sum(coefficients)\n",
    "    return 1 / (1 + np.exp(-sumcoeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Loop each row in test_df and calculate prediction, TP, TN, FP, FN\n",
    "i = 0\n",
    "cutoff = 0.5 # probability cutoff for prediction\n",
    "for index, row in test_df.iterrows():\n",
    "    # get commentId\n",
    "    comment_id = row['commentId']\n",
    "\n",
    "    # open training file for test row\n",
    "    filename = f\"./training_files/{comment_id}.csv\"\n",
    "    train_df = pd.read_csv(filename, low_memory=False)\n",
    "\n",
    "    # set target variable\n",
    "    y = train_df['classification']\n",
    "\n",
    "    # set independent variables\n",
    "    cols_to_drop = ['classification',\n",
    "                    'commentId',\n",
    "                    'comment',\n",
    "                    'comment_processed',\n",
    "                    'word_phrase_list',\n",
    "                    'similarity_score']\n",
    "    X = train_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # set weight to similarity score\n",
    "    sample_weights = train_df['similarity_score']\n",
    "\n",
    "    # Do logistic regression modeling with similarity_score as weight\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y, sample_weight = sample_weights)\n",
    "    \n",
    "    # create a column in the test_df for the predicted probability \n",
    "    test_df.at[index, 'probability'] = calculate_probability(log_reg.intercept_[0], log_reg.coef_[0]) \n",
    "\n",
    "    # calculate prediction from probability using cutoff\n",
    "    test_df.at[index, 'prediction'] = 1 if test_df.at[index, 'probability'] >= cutoff else 0\n",
    "\n",
    "    # calculate calibration\n",
    "    test_df.at[index, 'calibration'] = abs(test_df.at[index, 'probability'] - test_df.at[index, 'classification'])\n",
    "    \n",
    "    # Calculate TP, TN, FP, FN\n",
    "    test_df.at[index, 'TP'] = 1 if (test_df.at[index, 'prediction'] == 1 and test_df.at[index, 'classification'] == 1) else 0\n",
    "    test_df.at[index, 'TN'] = 1 if (test_df.at[index, 'prediction'] == 0 and test_df.at[index, 'classification'] == 0) else 0\n",
    "    test_df.at[index, 'FP'] = 1 if (test_df.at[index, 'prediction'] == 1 and test_df.at[index, 'classification'] == 0) else 0\n",
    "    test_df.at[index, 'FN'] = 1 if (test_df.at[index, 'prediction'] == 0 and test_df.at[index, 'classification'] == 1) else 0\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store file with corrected spelling for data checkpoint purposes\n",
    "test_df.to_csv('./data/test_df_completed_alpha80.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 72.86%\n",
      "Average of calibration: 0.33\n",
      "Standard deviation of calibration: 0.23\n"
     ]
    }
   ],
   "source": [
    "# For entire test_df calculate accuracy\n",
    "TP = test_df['TP'].sum()\n",
    "TN = test_df['TN'].sum()\n",
    "FP = test_df['FP'].sum()\n",
    "FN = test_df['FN'].sum()\n",
    "accuracy = round((TP + TN) / (TP + TN + FP + FN) * 100, 2)\n",
    "\n",
    "# Calculate average calibration and its standard deviation\n",
    "average_calibration = round(test_df['calibration'].mean(),2)\n",
    "std_dev_calibration = round(test_df['calibration'].std(),2)\n",
    "\n",
    "\n",
    "print(f\"Model accuracy: {accuracy}%\")\n",
    "print(f\"Average of calibration: {average_calibration}\")\n",
    "print(f\"Standard deviation of calibration: {std_dev_calibration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
